{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0aY1xpQPsMnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: IMPORT LIBRARY\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Kita pakai pandas buat handle CSV dan eksplorasi data\n",
        "# MinMaxScaler buat normalisasi nanti\n",
        "\n",
        "# STEP 2: BACA KETIGA CSV\n",
        "df1 = pd.read_csv('/content/Badminton_Match_Result_Dataset_1.csv')\n",
        "df2 = pd.read_csv('/content/Badminton_Match_Result_Dataset_2.csv')\n",
        "df3 = pd.read_csv('/content/Badminton_Match_Result_Dataset_3.csv')\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Baca ketiga dataset dan simpan masing-masing ke variabel\n",
        "\n",
        "# STEP 3: CEK ISI DATASET\n",
        "print(\"Dataset 1:\")\n",
        "print(df1.head())\n",
        "print(\"\\nDataset 2:\")\n",
        "print(df2.head())\n",
        "print(\"\\nDataset 3:\")\n",
        "print(df3.head())\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Kita print 5 baris pertama buat lihat isi dan struktur kolom\n",
        "\n",
        "# STEP 4: GABUNGKAN DATASET\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Gabungin semua dataset jadi satu dataframe\n",
        "\n",
        "# STEP 5: CEK MISSING VALUE\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Cek apakah ada data yang kosong (missing/null)\n",
        "\n",
        "# STEP 6: DATA CLEANING (contoh: drop NA atau isi nilai kosong)\n",
        "# Misalnya kita drop baris yang ada nilai kosong\n",
        "df_cleaned = df.dropna()\n",
        "\n",
        "# üìå CATATAN:\n",
        "# Atau bisa juga pake df.fillna() kalau mau isi nilai kosong\n",
        "\n",
        "# STEP 7: NORMALISASI (fitur numerik aja)\n",
        "# Misalnya kita normalisasi semua kolom numerik\n",
        "numerical_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "scaler = MinMaxScaler()\n",
        "df_cleaned[numerical_cols] = scaler.fit_transform(df_cleaned[numerical_cols])\n",
        "\n",
        "# üìå CATATAN:\n",
        "# MinMaxScaler ngeskalain data numerik ke range 0-1\n",
        "# Hati-hati: Ini harusnya dilakukan setelah cleaning\n",
        "\n",
        "# STEP 8: CEK DATASET HASILNYA\n",
        "print(\"\\nData setelah gabung, dibersihkan, dan dinormalisasi:\")\n",
        "print(df_cleaned.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "SMHARTcgjPlj",
        "outputId": "a4200c01-f8e3-4986-aef5-91d677cd0add"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1:\n",
            "  team_1;team_2;t1_p1_condition;t1_p2_condition;t2_p1_condition;t2_p2_condition;score\n",
            "0  David/Moel;Wawo/Angga;Recovery;Injured;Injured...                                 \n",
            "1  Arya/David;Dennis/Eka;Injured;Fit;Fit;Injured;...                                 \n",
            "2  Eka/David;Wawo/Arya;Fit;Recovery;Recovery;Fit;...                                 \n",
            "3  David/Eka;Wirawan/Arya;Sick;Fit;Injured;Recove...                                 \n",
            "4  Wawo/Arya;Eka/Dennis;Injured;Sick;Fit;Injured;...                                 \n",
            "\n",
            "Dataset 2:\n",
            "  tim_1;tim_2;kondisi_team1_player1;kondisi_team1_player2;kondisi_team2_player1;kondisi_team2_player2;skor\n",
            "0  David/Moel;Wawo/Angga;Recovery;Injured;Injured...                                                      \n",
            "1  Arya/David;Dennis/Eka;Injured;Fit;Fit;Injured;...                                                      \n",
            "2  Eka/David;Wawo/Arya;Fit;Recovery;Recovery;Fit;...                                                      \n",
            "3  David/Eka;Wirawan/Arya;Sick;Fit;Injured;Recove...                                                      \n",
            "4  Wawo/Arya;Eka/Dennis;Injured;Sick;Fit;Injured;...                                                      \n",
            "\n",
            "Dataset 3:\n",
            "  tim_1;tim_2;kondisi_team1_player1;kondisi_team1_player2;kondisi_team2_player1;kondisi_team2_player2;score\n",
            "0  David/Moel;Wawo/Angga;Pemulihan;Cedera;Cedera;...                                                       \n",
            "1  Arya/David;Dennis/Eka;Cedera;Sehat;Sehat;Ceder...                                                       \n",
            "2  Eka/David;Wawo/Arya;Sehat;Pemulihan;Pemulihan;...                                                       \n",
            "3  David/Eka;Wirawan/Arya;Sakit;Sehat;Cedera;Pemu...                                                       \n",
            "4  Wawo/Arya;Eka/Dennis;Cedera;Sakit;Sehat;Cedera...                                                       \n",
            "\n",
            "Missing Values:\n",
            "team_1;team_2;t1_p1_condition;t1_p2_condition;t2_p1_condition;t2_p2_condition;score                          5000\n",
            "tim_1;tim_2;kondisi_team1_player1;kondisi_team1_player2;kondisi_team2_player1;kondisi_team2_player2;skor     4000\n",
            "tim_1;tim_2;kondisi_team1_player1;kondisi_team1_player2;kondisi_team2_player1;kondisi_team2_player2;score    3000\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "at least one array or dtype is required",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b6acd622c273>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mnumerical_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# üìå CATATAN:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m         )\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpandas_requires_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;31m# Force object if any of the dtypes is an object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí• Masalah yang Muncul:\n",
        "1. CSV pakai delimiter ; (titik koma)\n",
        "Makanya waktu read_csv(), datanya dibaca sebagai 1 kolom besar, bukan kolom-kolom terpisah. Itu kenapa waktu df.head() keluar, kolomnya masih kayak gini:\n",
        "\n",
        "Copy\n",
        "Edit\n",
        "team_1;team_2;t1_p1_condition;t1_p2_condition;t2_p1_condition;t2_p2_condition;score\n",
        "Semua masih nyatu.\n",
        "\n",
        "2. Jumlah kolom beda dan nama beda di tiap dataset\n",
        "Dataset 2 & 3 pake bahasa Indonesia dan beda naming.\n",
        "Dataset 3 bahkan pake istilah kayak \"Cedera\", \"Pemulihan\" dll ‚Äî jadi ada perlu translasi kondisi juga nanti."
      ],
      "metadata": {
        "id": "XJdo0EKWj0R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baca ulang dengan delimiter yang benar\n",
        "df1 = pd.read_csv('/content/Badminton_Match_Result_Dataset_1.csv', delimiter=';')\n",
        "df2 = pd.read_csv('/content/Badminton_Match_Result_Dataset_2.csv', delimiter=';')\n",
        "df3 = pd.read_csv('/content/Badminton_Match_Result_Dataset_3.csv', delimiter=';')"
      ],
      "metadata": {
        "id": "PIrp-pH5juHZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Rename kolom biar konsisten (bisa pakai bahasa Inggris semua)\n",
        "# Rename dataset 2\n",
        "df2.columns = ['team_1', 'team_2', 't1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition', 'score']\n",
        "\n",
        "# Rename dataset 3\n",
        "df3.columns = ['team_1', 'team_2', 't1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition', 'score']"
      ],
      "metadata": {
        "id": "fq-f5dBsj_qs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Translate nilai kondisi dari Bahasa Indonesia ke Inggris (khusus dataset 3)\n",
        "# Buat kamus translasi\n",
        "translation_map = {\n",
        "    'Sehat': 'Fit',\n",
        "    'Cedera': 'Injured',\n",
        "    'Pemulihan': 'Recovery',\n",
        "    'Sakit': 'Sick'\n",
        "}\n",
        "\n",
        "# Replace di kolom kondisi\n",
        "condition_cols = ['t1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition']\n",
        "for col in condition_cols:\n",
        "    df3[col] = df3[col].replace(translation_map)\n"
      ],
      "metadata": {
        "id": "6jV1LLkxkC39"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîß Step 4: Gabung semua dataset\n",
        "\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)"
      ],
      "metadata": {
        "id": "HDLFZSsdkLgW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())  # Cek missing values\n",
        "df_cleaned = df.dropna()  # Drop baris kosong"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fThBJH3OkSUi",
        "outputId": "f801e7cf-a691-455c-b7b1-d74e36116f95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "team_1             4\n",
            "team_2             1\n",
            "t1_p1_condition    3\n",
            "t1_p2_condition    2\n",
            "t2_p1_condition    1\n",
            "t2_p2_condition    1\n",
            "score              3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek 5 baris pertama\n",
        "print(df_cleaned.head())\n",
        "\n",
        "# Cek jumlah baris & kolom\n",
        "print(\"\\nShape of dataset:\", df_cleaned.shape)\n",
        "\n",
        "# Cek tipe data tiap kolom\n",
        "print(\"\\nData types:\")\n",
        "print(df_cleaned.dtypes)\n",
        "\n",
        "# Cek jumlah data unik per kolom (buat tau kolom kategori)\n",
        "print(\"\\nUnique values per column:\")\n",
        "for col in df_cleaned.columns:\n",
        "    print(f\"{col}: {df_cleaned[col].nunique()} unique values\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vanpxLFQkdkC",
        "outputId": "c7c7c925-c116-4ef0-a698-3cb97ef768f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       team_1        team_2 t1_p1_condition t1_p2_condition t2_p1_condition  \\\n",
            "0  David/Moel    Wawo/Angga        Recovery         Injured         Injured   \n",
            "1  Arya/David    Dennis/Eka         Injured             Fit             Fit   \n",
            "2   Eka/David     Wawo/Arya             Fit        Recovery        Recovery   \n",
            "3   David/Eka  Wirawan/Arya            Sick             Fit         Injured   \n",
            "4   Wawo/Arya    Eka/Dennis         Injured            Sick             Fit   \n",
            "\n",
            "  t2_p2_condition score  \n",
            "0            Sick  '2-0  \n",
            "1         Injured  '2-1  \n",
            "2             Fit  '1-2  \n",
            "3        Recovery  '2-1  \n",
            "4         Injured  '1-2  \n",
            "\n",
            "Shape of dataset: (5985, 7)\n",
            "\n",
            "Data types:\n",
            "team_1             object\n",
            "team_2             object\n",
            "t1_p1_condition    object\n",
            "t1_p2_condition    object\n",
            "t2_p1_condition    object\n",
            "t2_p2_condition    object\n",
            "score              object\n",
            "dtype: object\n",
            "\n",
            "Unique values per column:\n",
            "team_1: 56 unique values\n",
            "team_2: 56 unique values\n",
            "t1_p1_condition: 4 unique values\n",
            "t1_p2_condition: 4 unique values\n",
            "t2_p1_condition: 4 unique values\n",
            "t2_p2_condition: 4 unique values\n",
            "score: 5 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† ANALISIS DATASET LO SEKARANG:\n",
        "‚úÖ Kondisi Data:\n",
        "5985 baris, lumayan banyak! Cukup untuk bikin model ML belajar.\n",
        "\n",
        "Semua kolom condition udah bersih dan punya 4 kategori (Fit, Sick, Injured, Recovery).\n",
        "\n",
        "Kolom score kayaknya nunjukin hasil pertandingan, contoh: '2-0, '1-2, dll. Tapi masih ada ' di depannya ‚Üí kita bersihin nanti.\n",
        "\n",
        "Kolom team_1 dan team_2 itu kombinasi pemain, mungkin bisa diproses lebih jauh kalau mau analisis performa pemain tertentu (optional sih)."
      ],
      "metadata": {
        "id": "6R_aa1uHk7uB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ NEXT: Feature Engineering\n",
        "üéØ Tujuan:\n",
        "Nyiapin fitur-fitur (X) yang bisa dipakai buat memprediksi hasil pertandingan (y). Kita bisa mulai dari:\n",
        "\n",
        "1. üßº Bersihin kolom score\n",
        "Kita buang tanda ' dan ekstrak siapa yang menang:\n"
      ],
      "metadata": {
        "id": "YxxlijTgk98B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bersihin tanda '\n",
        "df_cleaned['score'] = df_cleaned['score'].str.replace(\"'\", \"\")\n",
        "\n",
        "# Tambahin kolom 'winner' berdasarkan skor\n",
        "def determine_winner(score):\n",
        "    try:\n",
        "        team1, team2 = map(int, score.split('-'))\n",
        "        if team1 > team2:\n",
        "            return 'team_1'\n",
        "        elif team2 > team1:\n",
        "            return 'team_2'\n",
        "        else:\n",
        "            return 'draw'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "df_cleaned['winner'] = df_cleaned['score'].apply(determine_winner)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEV7ie0LlFda",
        "outputId": "1b471431-2be6-487b-c96d-3b643666eb19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-234b282af399>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['score'] = df_cleaned['score'].str.replace(\"'\", \"\")\n",
            "<ipython-input-11-234b282af399>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['winner'] = df_cleaned['score'].apply(determine_winner)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. üî¢ Encode kategori condition jadi angka\n",
        "# Mapping kondisi ke angka\n",
        "condition_map = {\n",
        "    'Fit': 3,\n",
        "    'Recovery': 2,\n",
        "    'Injured': 1,\n",
        "    'Sick': 0\n",
        "}\n",
        "\n",
        "for col in ['t1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition']:\n",
        "    df_cleaned[col] = df_cleaned[col].map(condition_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nPiVqL2lIVC",
        "outputId": "9bab0707-501e-473d-88f2-16402b152714"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-cedc956425fd>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned[col] = df_cleaned[col].map(condition_map)\n",
            "<ipython-input-12-cedc956425fd>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned[col] = df_cleaned[col].map(condition_map)\n",
            "<ipython-input-12-cedc956425fd>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned[col] = df_cleaned[col].map(condition_map)\n",
            "<ipython-input-12-cedc956425fd>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned[col] = df_cleaned[col].map(condition_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. ‚ûï Bikin fitur baru (optional tapi powerful)\n",
        "Misalnya:\n",
        "\n",
        "Total kondisi pemain per tim\n",
        "\n",
        "Apakah ada pemain yang sakit? (binary)"
      ],
      "metadata": {
        "id": "N4dRpYJulQSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah skor kondisi per tim (semakin tinggi = makin fit)\n",
        "df_cleaned['team_1_total_condition'] = df_cleaned['t1_p1_condition'] + df_cleaned['t1_p2_condition']\n",
        "df_cleaned['team_2_total_condition'] = df_cleaned['t2_p1_condition'] + df_cleaned['t2_p2_condition']\n",
        "\n",
        "# Apakah ada pemain yang sakit di tiap tim?\n",
        "df_cleaned['team_1_has_sick'] = ((df_cleaned['t1_p1_condition'] == 0) | (df_cleaned['t1_p2_condition'] == 0)).astype(int)\n",
        "df_cleaned['team_2_has_sick'] = ((df_cleaned['t2_p1_condition'] == 0) | (df_cleaned['t2_p2_condition'] == 0)).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbOBfrePlOd5",
        "outputId": "a5589d9c-6f61-4ac6-ff39-082257f25a7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0072f8d8bc30>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['team_1_total_condition'] = df_cleaned['t1_p1_condition'] + df_cleaned['t1_p2_condition']\n",
            "<ipython-input-13-0072f8d8bc30>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['team_2_total_condition'] = df_cleaned['t2_p1_condition'] + df_cleaned['t2_p2_condition']\n",
            "<ipython-input-13-0072f8d8bc30>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['team_1_has_sick'] = ((df_cleaned['t1_p1_condition'] == 0) | (df_cleaned['t1_p2_condition'] == 0)).astype(int)\n",
            "<ipython-input-13-0072f8d8bc30>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['team_2_has_sick'] = ((df_cleaned['t2_p1_condition'] == 0) | (df_cleaned['t2_p2_condition'] == 0)).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitur dan target\n",
        "features = ['t1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition',\n",
        "            'team_1_total_condition', 'team_2_total_condition',\n",
        "            'team_1_has_sick', 'team_2_has_sick']\n",
        "\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned['winner']\n"
      ],
      "metadata": {
        "id": "xuYme6wulUrI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå CATATAN: Ini asumsi lo udah jalanin step 1 dan 2 ya\n",
        "\n",
        "# --- HEAD (5 data pertama)\n",
        "print(\"üîπ Head (5 baris pertama):\")\n",
        "print(df_cleaned.head())\n",
        "\n",
        "# --- TAIL (5 data terakhir)\n",
        "print(\"\\nüîπ Tail (5 baris terakhir):\")\n",
        "print(df_cleaned.tail())\n",
        "\n",
        "# --- SHAPE (jumlah baris dan kolom)\n",
        "print(\"\\nüîπ Shape of dataset:\")\n",
        "print(df_cleaned.shape)\n",
        "\n",
        "# --- NAMA KOLOM\n",
        "print(\"\\nüîπ Kolom-kolom:\")\n",
        "print(df_cleaned.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGoOVx97lgVu",
        "outputId": "6fd4448e-88a7-4ab9-f292-2b4bc05375b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Head (5 baris pertama):\n",
            "       team_1        team_2  t1_p1_condition  t1_p2_condition  \\\n",
            "0  David/Moel    Wawo/Angga                2                1   \n",
            "1  Arya/David    Dennis/Eka                1                3   \n",
            "2   Eka/David     Wawo/Arya                3                2   \n",
            "3   David/Eka  Wirawan/Arya                0                3   \n",
            "4   Wawo/Arya    Eka/Dennis                1                0   \n",
            "\n",
            "   t2_p1_condition  t2_p2_condition score  winner  team_1_total_condition  \\\n",
            "0                1                0   2-0  team_1                       3   \n",
            "1                3                1   2-1  team_1                       4   \n",
            "2                2                3   1-2  team_2                       5   \n",
            "3                1                2   2-1  team_1                       3   \n",
            "4                3                1   1-2  team_2                       1   \n",
            "\n",
            "   team_2_total_condition  team_1_has_sick  team_2_has_sick  \n",
            "0                       1                0                1  \n",
            "1                       4                0                0  \n",
            "2                       5                0                0  \n",
            "3                       3                1                0  \n",
            "4                       4                1                0  \n",
            "\n",
            "üîπ Tail (5 baris terakhir):\n",
            "            team_1        team_2  t1_p1_condition  t1_p2_condition  \\\n",
            "5995    Arya/David     Angga/Eka                0                3   \n",
            "5996    Angga/Arya   Dennis/Wawo                2                3   \n",
            "5997     Arya/Wawo  Dennis/Angga                0                2   \n",
            "5998  Arya/Wirawan      Moel/Eka                3                3   \n",
            "5999  Wirawan/Moel     Eka/Angga                2                3   \n",
            "\n",
            "      t2_p1_condition  t2_p2_condition score  winner  team_1_total_condition  \\\n",
            "5995                1                3   1-2  team_2                       3   \n",
            "5996                1                2   2-0  team_1                       5   \n",
            "5997                2                2   2-0  team_1                       2   \n",
            "5998                2                0   1-2  team_2                       6   \n",
            "5999                2                3   0-2  team_2                       5   \n",
            "\n",
            "      team_2_total_condition  team_1_has_sick  team_2_has_sick  \n",
            "5995                       4                1                0  \n",
            "5996                       3                0                0  \n",
            "5997                       4                1                0  \n",
            "5998                       2                0                1  \n",
            "5999                       5                0                0  \n",
            "\n",
            "üîπ Shape of dataset:\n",
            "(5985, 12)\n",
            "\n",
            "üîπ Kolom-kolom:\n",
            "['team_1', 'team_2', 't1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition', 'score', 'winner', 'team_1_total_condition', 'team_2_total_condition', 'team_1_has_sick', 'team_2_has_sick']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXDYltuTlmuQ",
        "outputId": "e024493e-fca5-4062-8319-c8780749ad95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5985 entries, 0 to 5999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   team_1                  5985 non-null   object\n",
            " 1   team_2                  5985 non-null   object\n",
            " 2   t1_p1_condition         5985 non-null   int64 \n",
            " 3   t1_p2_condition         5985 non-null   int64 \n",
            " 4   t2_p1_condition         5985 non-null   int64 \n",
            " 5   t2_p2_condition         5985 non-null   int64 \n",
            " 6   score                   5985 non-null   object\n",
            " 7   winner                  5985 non-null   object\n",
            " 8   team_1_total_condition  5985 non-null   int64 \n",
            " 9   team_2_total_condition  5985 non-null   int64 \n",
            " 10  team_1_has_sick         5985 non-null   int64 \n",
            " 11  team_2_has_sick         5985 non-null   int64 \n",
            "dtypes: int64(8), object(4)\n",
            "memory usage: 607.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mantap, ini request analisis head-to-head antara dua pemain, Arya vs Dennis, dengan aturan penting:\n",
        "\n",
        "‚ùó Kalau Arya dan Dennis ada di tim yang sama, match itu gak dihitung.\n",
        "\n",
        "‚úÖ Step-by-step logic:\n",
        "Cek baris data yang mengandung Arya dan Dennis.\n",
        "\n",
        "Pastikan mereka ada di tim yang berbeda (bukan satu tim).\n",
        "\n",
        "Lihat tim mana yang menang, apakah timnya Arya atau Dennis.\n",
        "\n",
        "Hitung total kemenangan Arya dan Dennis."
      ],
      "metadata": {
        "id": "RuTQ_d-VlvtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil match yang melibatkan Arya DAN Dennis\n",
        "h2h_matches = df_cleaned[\n",
        "    df_cleaned['team_1'].str.contains('Arya') & df_cleaned['team_2'].str.contains('Dennis') |\n",
        "    df_cleaned['team_2'].str.contains('Arya') & df_cleaned['team_1'].str.contains('Dennis')\n",
        "]\n",
        "\n",
        "# Filter match yang TIDAK satu tim\n",
        "# Jadi exclude kalau dalam 1 team ada Arya & Dennis\n",
        "h2h_filtered = h2h_matches[~(\n",
        "    h2h_matches['team_1'].str.contains('Arya') & h2h_matches['team_1'].str.contains('Dennis') |\n",
        "    h2h_matches['team_2'].str.contains('Arya') & h2h_matches['team_2'].str.contains('Dennis')\n",
        ")]\n",
        "\n",
        "# Hitung menang siapa\n",
        "arya_win = ((h2h_filtered['winner'] == 'team_1') & (h2h_filtered['team_1'].str.contains('Arya')) |\n",
        "            (h2h_filtered['winner'] == 'team_2') & (h2h_filtered['team_2'].str.contains('Arya'))).sum()\n",
        "\n",
        "dennis_win = ((h2h_filtered['winner'] == 'team_1') & (h2h_filtered['team_1'].str.contains('Dennis')) |\n",
        "              (h2h_filtered['winner'] == 'team_2') & (h2h_filtered['team_2'].str.contains('Dennis'))).sum()\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(f\"üîπ Total Match Arya vs Dennis (bukan rekanan): {len(h2h_filtered)}\")\n",
        "print(f\"‚úÖ Arya menang: {arya_win}\")\n",
        "print(f\"‚úÖ Dennis menang: {dennis_win}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHNdox-clnMo",
        "outputId": "f6765391-055b-4b5a-a061-cc7b68df9db0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Total Match Arya vs Dennis (bukan rekanan): 886\n",
            "‚úÖ Arya menang: 447\n",
            "‚úÖ Dennis menang: 439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oke, bro. Kita lanjut ke pertanyaan kelima:\n",
        "\n",
        "Hitung berapa kali David menang dengan skor 2-0\n",
        "\n",
        "‚úÖ Logika langkahnya:\n",
        "Cari baris di mana David ada di team_1 atau team_2.\n",
        "\n",
        "Cek tim mana yang menang (winner == team_1 atau team_2).\n",
        "\n",
        "Pastikan skornya '2-0'.\n",
        "\n",
        "Hitung jumlah baris yang memenuhi semua kondisi itu."
      ],
      "metadata": {
        "id": "ud36WsdimDzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cari match yang dimenangkan oleh David dengan skor 2-0\n",
        "david_win_2_0 = df_cleaned[\n",
        "    ((df_cleaned['winner'] == 'team_1') & df_cleaned['team_1'].str.contains('David')) |\n",
        "    ((df_cleaned['winner'] == 'team_2') & df_cleaned['team_2'].str.contains('David'))\n",
        "]\n",
        "\n",
        "# Filter lagi yang skornya 2-0\n",
        "david_win_2_0 = david_win_2_0[david_win_2_0['score'] == '2-0']\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(f\"üè∏ David menang dengan skor 2-0 sebanyak: {len(david_win_2_0)} kali\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsR1Iplll2zS",
        "outputId": "3f92cafa-2744-4055-af51-249b33f21c48"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè∏ David menang dengan skor 2-0 sebanyak: 375 kali\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù Catatan:\n",
        "Ini ngasumsikan kolom winner dan score udah bener dari feature engineering sebelumnya.\n",
        "\n",
        "'score' harus '2-0' dalam bentuk string ‚Äî pastiin gak ada spasi atau kutip aneh (kalau sebelumnya ada '2-0, pastikan udah dibersihin).\n",
        "\n",
        "Kalau sebelumnya belum dibersihin, bisa tambahin ini di preprocessing step:\n",
        "\n",
        "df_cleaned['score'] = df_cleaned['score'].str.replace(\"'\", \"\").str.strip()\n"
      ],
      "metadata": {
        "id": "7d8q3dh4mNYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oke lanjut, bro! Kali ini pertanyaannya:\n",
        "\n",
        "Hitung berapa kali Moel kalah dengan skor 1-2\n",
        "\n",
        "‚úÖ Step-by-step logic:\n",
        "Cari match di mana Moel ada di team_1 atau team_2.\n",
        "\n",
        "Pastikan Moel ada di tim yang kalah.\n",
        "\n",
        "Skornya harus '1-2'.\n",
        "\n",
        "Hitung totalnya."
      ],
      "metadata": {
        "id": "RXNuIiQ6mUMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cari semua match yang skor akhirnya 1-2\n",
        "moel_match = df_cleaned[df_cleaned['score'] == '1-2']\n",
        "\n",
        "# Cari match di mana Moel kalah (Moel ada di tim yang bukan 'winner')\n",
        "moel_kalah_1_2 = moel_match[\n",
        "    ((moel_match['team_1'].str.contains('Moel')) & (moel_match['winner'] == 'team_2')) |\n",
        "    ((moel_match['team_2'].str.contains('Moel')) & (moel_match['winner'] == 'team_1'))\n",
        "]\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(f\"üòì Moel kalah dengan skor 1-2 sebanyak: {len(moel_kalah_1_2)} kali\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcV7Bn1emawo",
        "outputId": "a6d069e0-0ae5-4554-a044-946f082f45c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üòì Moel kalah dengan skor 1-2 sebanyak: 365 kali\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù Notes:\n",
        "Ini udah otomatis cek siapa yang kalah berdasarkan kolom winner.\n",
        "\n",
        "Skor '1-2' harus sudah dibersihin juga ya (kayak hilangin ' dan spasi).\n",
        "\n",
        "Kalau score sebelumnya masih ada ' (contoh: '1-2), pastiin kamu udah pakai:\n",
        "\n",
        "df_cleaned['score'] = df_cleaned['score'].str.replace(\"'\", \"\").str.strip()\n"
      ],
      "metadata": {
        "id": "rkK8YuV5mgMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_Jy2dRNMmvj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Split data untuk training dan testing, persentasenya silahkan ditentukan sendiri **\n",
        "\n",
        "üéØ Tujuan Split:\n",
        "Split data itu tujuannya buat melatih model (training) dan mengevaluasi performa model (testing) secara adil dan objektif. Jadi model lo gak cuma jago di data latih doang (overfitting), tapi bisa generalisasi ke data baru.\n",
        "\n",
        "‚úÖ Yang Perlu Dipersiapkan:\n",
        "# 1. Feature & Target (X & y)\n",
        "Lo harus tahu:\n",
        "\n",
        "Fitur-fitur apa yang mau dipake buat prediksi? (contoh: kondisi pemain)\n",
        "\n",
        "Target-nya apa? (contoh: winner, atau score, tergantung apa yang mau diprediksi). contoh\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "X = df_cleaned[['t1_p1_condition', 't1_p2_condition', 't2_p1_condition', 't2_p2_condition']]\n",
        "y = df_cleaned['winner']\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Tapi inget:\n",
        "\n",
        "Kalau kolom masih kategorikal (kayak Fit, Sick, dll), harus di-encode dulu.\n",
        "\n",
        "Kalau mau prediksi score atau winner, pastiin targetnya masuk akal untuk classification atau regression.\n",
        "\n",
        "\n",
        "# 2. Encoding Kategorikal\n",
        "Model machine learning gak bisa baca teks. Jadi lo harus ubah semua kategori ke angka:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Label encode semua fitur\n",
        "label_enc = LabelEncoder()\n",
        "X_encoded = X.apply(label_enc.fit_transform)\n",
        "\n",
        "# Encode target juga\n",
        "y_encoded = label_enc.fit_transform(y)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# 3. Split Data\n",
        "\n",
        "\n",
        "```\n",
        "Pakai train_test_split dari scikit-learn:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "test_size=0.2 artinya 20% buat test, 80% buat train (umum banget).\n",
        "\n",
        "random_state biar hasilnya konsisten.\n",
        "\n",
        "# 4. (Optional) Imbalance Check\n",
        "Kalau target-nya (misal winner) sangat tidak seimbang (misal team_1 menang 90%), lo bisa pertimbangin:\n",
        "\n",
        "pakai stratify=y saat split\n",
        "\n",
        "atau pakai teknik balancing (misal SMOTE, undersampling, dll).\n",
        "\n",
        "\n",
        "```\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "apxpSdulmxUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ Target yang Bisa Diprediksi dari Dataset:\n",
        "# 1. Winner (siapa yang menang?) üèÜ\n",
        "Kita bisa bikin kolom baru winner dari kolom score, misalnya:\n",
        "\n",
        "Kalau score == '2-0' atau '2-1' ‚Üí berarti team_1 menang.\n",
        "\n",
        "Kalau score == '0-2' atau '1-2' ‚Üí berarti team_2 menang.\n",
        "\n",
        "üìå Ini cocok banget buat Classification Task:\n",
        "\n",
        "Kelas: team_1_win vs team_2_win\n",
        "\n",
        "# 2. Score (nilai akhir: 2-0, 2-1, dst) üî¢\n",
        "Kita bisa prediksi langsung nilai score, tapi ini tricky:\n",
        "\n",
        "Bentuk skornya bukan angka asli (bukan 1, 2, 3...) tapi string kayak '2-1'.\n",
        "\n",
        "Bisa diubah ke kategori, jadi ini juga bisa jadi Classification Task:\n",
        "\n",
        "Kelas: '2-0', '2-1', '1-2', '0-2', dll.\n",
        "\n",
        "# 3. Point Gap (selisih skor) ‚ûñ\n",
        "Misal dari 2-1 ‚Üí gap = +1 buat team_1\n",
        "\n",
        "Ini bisa dibuat jadi Regression Task (output berupa angka)\n",
        "\n",
        "# 4. Apakah menang dengan skor telak? (Misal 2-0) üí•\n",
        "Ini bisa jadi Binary Classification:\n",
        "\n",
        "True kalau menang 2-0, False kalau 2-1, atau kalah.\n",
        "\n",
        "# 5. Prediksi peluang menang berdasarkan kondisi pemain ü§ïüí™\n",
        "Kita bisa fokus di kondisi pemain sebagai fitur, lalu lihat siapa yang menang.\n",
        "\n",
        "Ini mirip dengan prediksi winner, tapi bisa digabung dengan feature engineering lebih lanjut kayak rating pemain (kalau ada), atau performa sebelumnya.\n",
        "\n",
        "üö® Yang Gak Bisa Diprediksi (dari data yang sekarang):\n",
        "Siapa pemain individu yang paling berpengaruh (butuh data tambahan)\n",
        "\n",
        "Skor per game/set (gak tersedia)\n",
        "\n",
        "Lokasi pertandingan, wasit, cuaca, dll (gak tersedia di dataset)"
      ],
      "metadata": {
        "id": "vQO-PfC8oQcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['score'])\n",
        "y = df['score']\n"
      ],
      "metadata": {
        "id": "hScOAVFvp_ba"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df\n"
      ],
      "metadata": {
        "id": "DbI77x6pqArM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ Step 1: Split Data untuk Training dan Testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Asumsikan target yang mau kita prediksi adalah skor\n",
        "X = df_final.drop(columns=['score'])  # fitur\n",
        "y = df_final['score']  # label\n",
        "\n",
        "# Encoding (wajib kalau ada kategori)\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Split 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# üí° Catatan: Di sini kita pakai score sebagai label, tapi nanti lo bisa ganti ke winner kalo mau prediksi menang/kalah."
      ],
      "metadata": {
        "id": "zERpx_Stpma_"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}